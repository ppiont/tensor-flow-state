{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_clean.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppiont/tensor-flow-state/blob/master/1_data_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ7f4fQLqMXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnge-3rHqWUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd \"/gdrive/My Drive/tensor-flow-state/tensor-flow-state\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtrvUXW94U4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RnHSY3Xsbpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"data/\"\n",
        "sensor_list = [\"RWS01_MONIBAS_0021hrl0403ra.csv\", \"RWS01_MONIBAS_0021hrl0409ra.csv\", \"RWS01_MONIBAS_0021hrl0414ra.csv\", \"RWS01_MONIBAS_0021hrl0420ra.csv\", \"RWS01_MONIBAS_0021hrl0426ra.csv\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4GQG9DY3J_F",
        "colab_type": "text"
      },
      "source": [
        "### Clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmXOKIfAwgrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "def dateparse (time_in_secs):\n",
        "    # Unix/epoch time to \"YYYY-MM-DD HH:MM:SS\"\n",
        "    return datetime.datetime.fromtimestamp(float(time_in_secs))\n",
        "\n",
        "def repair_datetime_index(df, freq = \"T\"):\n",
        "    df = df.loc[~df.index.duplicated(keep = \"first\")] # remove duplicate date time indexes\n",
        "    df = df.reindex(pd.date_range(start = df.index.min(), end = df.index.max(), freq = freq)) # add missing date time indexes\n",
        "    return df\n",
        "\n",
        "def fix_values(df):\n",
        "    # The order of these operations is currently important! Pay attention when making changes\n",
        "    df[\"speed_limit\"] = np.where((df.index.hour < 19) & (df.index.hour >= 6), 100, 120)\n",
        "    df.loc[df.flow < 0, \"flow\"] = np.nan # flow is either -2 (missing data) or 0 or positive. -2 to nan\n",
        "    df.loc[df.speed < -1, \"speed\"] = np.nan # -2 (missing data) as well as oddities (-1.33, an average over -2 and -1 lanes?) to nan \n",
        "    df.speed.mask(df.speed == -1, df.speed_limit, inplace = True) # -1 means no cars, setting it to speed limit\n",
        "    df.loc[(df.speed < 0) & (df.speed > -1), \"speed\"] = 0 # anything else below zero is between 0 and -1, occuring when some lanes have non-moving cars while others have have no cars.\n",
        "    df.speed.mask(df.speed > df.speed_limit, df.speed_limit, inplace = True) # cap speed at speed_limit, since higher speed dosn't add to representation\n",
        "    return df\n",
        "\n",
        "import os\n",
        "def reduce_cols(sensors, path_in = \"data/ndw_raw/\", path_out = \"data/\"):\n",
        "    for sensor in sensors:\n",
        "        df = pd.read_csv(os.path.join(path_in, sensor), header = None, \\\n",
        "                         usecols = [0, 86, 87], names = [\"timestamp\", \"speed\", \"flow\"], \\\n",
        "                         index_col = \"timestamp\", parse_dates = True, date_parser = dateparse)\n",
        "        df.flow /= 60 # change flow unit to min^-1\n",
        "        df = repair_datetime_index(df)\n",
        "        df = fix_values(df)        \n",
        "        df.to_csv(path_out + sensor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTUTI6Ivwgh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_cols(sensor_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNmTJSBP3ABY",
        "colab_type": "text"
      },
      "source": [
        "### Join Sensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y0yV1GR3AE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def join_sensors(sensor_list):\n",
        "    combined_df = pd.DataFrame({\"timestamp\": pd.date_range(start = \"2011-01-01\", end = \"2019-12-31\", freq = \"T\")})\n",
        "    combined_df.set_index(\"timestamp\", drop = True, inplace = True)\n",
        "    for i, sensor in enumerate(sensor_list):\n",
        "        # only add speed limit on the final sensor\n",
        "        if i == len(sensor_list) - 1:\n",
        "            df = pd.read_csv(data_dir + sensor + \".csv\", index_col = 0, parse_dates = True)\n",
        "            combined_df = combined_df.join(df, how = \"outer\", rsuffix = '_' + sensor)\n",
        "        else:\n",
        "            df = pd.read_csv(data_dir + sensor + \".csv\", usecols = [0, 1, 2], index_col = 0, parse_dates = True)\n",
        "            combined_df = combined_df.join(df, how = \"outer\", rsuffix = \"_\" + sensor)\n",
        "    combined_df.dropna(how = \"all\", axis = 0, inplace = True) # this works in all cases because speed_limit is never NA on a sensor df\n",
        "    return combined_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOF-7-DH3AIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join sensors to one table\n",
        "df = join_sensors(sensor_list)\n",
        "\n",
        "# Rename and reorder columns\n",
        "df.rename({\"speed_RWS01_MONIBAS_0021hrl0403ra\": \"speed_-2\", \"speed_RWS01_MONIBAS_0021hrl0409ra\": \"speed_-1\",\\\n",
        "           \"speed_RWS01_MONIBAS_0021hrl0420ra\": \"speed_+1\", \"speed_RWS01_MONIBAS_0021hrl0426ra\": \"speed_+2\",\\\n",
        "           \"flow_RWS01_MONIBAS_0021hrl0403ra\": \"flow_-2\", \"flow_RWS01_MONIBAS_0021hrl0409ra\": \"flow_-1\",\\\n",
        "           \"flow_RWS01_MONIBAS_0021hrl0420ra\": \"flow_+1\", \"flow_RWS01_MONIBAS_0021hrl0426ra\": \"flow_+2\"\\\n",
        "           }, axis = 1, inplace = True)\n",
        "col_order = [\"speed\", \"flow\", \"speed_-2\", \"speed_-1\",\"speed_+1\", \"speed_+2\", \"flow_-2\", \"flow_-1\", \"flow_+1\", \"flow_+2\", \"speed_limit\"]\n",
        "df = df[col_order]\n",
        "\n",
        "# Save table to csv\n",
        "df.to_csv(data_dir + \"combined_df.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrDjuh7i3AL0",
        "colab_type": "text"
      },
      "source": [
        "### Impute data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti2Y2snk4FwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"data/combined_df.csv\", index_col = 0, parse_dates = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu-qf0zY3APl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = [\"speed\", \"flow\", \"speed_-2\", \"speed_-1\",\"speed_+1\", \"speed_+2\", \"flow_-2\", \"flow_-1\", \"flow_+1\", \"flow_+2\", \"speed_limit\"]\n",
        "speed_cols = [\"speed\", \"speed_-2\", \"speed_-1\",\"speed_+1\", \"speed_+2\"]\n",
        "flow_cols = [\"flow\", \"flow_-2\", \"flow_-1\", \"flow_+1\", \"flow_+2\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPqnzTiC3jv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Where values are missing in one or more sensors, but are present in others, impute with mean of others\n",
        "def fill_na_row_mean(df):\n",
        "    row_avgs = df.mean(axis = 1).values.reshape(-1, 1)\n",
        "    df = df.fillna(0) + df.isna().values * row_avgs\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q57xMK6S3jy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "speed_df = fill_na_row_mean(df[speed_cols])\n",
        "flow_df = fill_na_row_mean(df[flow_cols])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgWSgxrh3j2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = speed_df.join(flow_df, how = 'inner').join(df[['speed_limit']], how = 'inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZC2hHl03j40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolate null vals for the first week of data of speed and flow cols\n",
        "def interpolate_week(df, cols):\n",
        "    week = 7 * 24 * 60\n",
        "    for col in cols: \n",
        "        df.iloc[:week, df.columns.get_loc(col)] = df[col][:week].interpolate(method = 'time')\n",
        "    return df\n",
        "\n",
        "# Replace remaining nulls with value from 1 week previous\n",
        "def shift_week(df, cols):\n",
        "    # Use RangeIndex for the this operation\n",
        "    df['timestamp'] = df.index\n",
        "    df.reset_index(drop = True, inplace = True)\n",
        "    week = 7 * 24 * 60\n",
        "    for col in cols:\n",
        "        col_index = df.columns.get_loc(col)\n",
        "        for row in df.itertuples():\n",
        "            if np.isnan(row[col_index + 1]):\n",
        "                df.iat[row[0], col_index] = df.iat[(row[0] - week), col_index]\n",
        "    # Return to DateTimeIndex again\n",
        "    df.set_index(pd.to_datetime(df.timestamp.values), inplace = True) \n",
        "    df.drop('timestamp', axis = 1, inplace = True)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLHJF-oi3ASk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = interpolate_week(df, cols)\n",
        "df = shift_week(df, cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_lyBI614aiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"data/df_imputed_week_shift.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6PavrY54ma1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"data/df_imputed_week_shift.csv\", index_col = 0, parse_dates = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w36E1fQk4n2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import holidays"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgz3j9ic4n5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['weekend'] = np.where(df.index.weekday > 4, 1, 0).astype(np.int16)\n",
        "df['holiday'] = np.array([int(x in holidays.NL()) for x in df.index]).astype(np.int16)\n",
        "df['speed_limit'] =  np.where(df.speed_limit > 110, 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXCdhd1_4n9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('data/df_imputed_week_shift_added_holiday_weekends')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}