{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_training.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMReUTe/rBf1kfhroCZfTz/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppiont/tensor-flow-state/blob/master/Model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSuzkeZcM2UE",
        "colab_type": "code",
        "outputId": "73f4d847-dc21-4a40-988c-8e12f5e06edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBC4ZppZNC3c",
        "colab_type": "code",
        "outputId": "719fc9a1-a6e9-4ce7-ee0c-fc01997a4caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd \"/gdrive/My Drive/tensor-flow-state/tensor-flow-state\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/tensor-flow-state/tensor-flow-state\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKD3KY8hNEqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"data/df_imputed_week_shift.csv\", index_col = 0, parse_dates = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbYIfvGqcui0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0 resample\n",
        "# 1 log transformere. \n",
        "# 2 difference ift. speed limit (som ogsaa skal vaere log transformeret)\n",
        "# 3 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzVAi95GfcBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = [\"speed\", \"flow\", \"speed_-2\", \"speed_-1\",\"speed_+1\", \"speed_+2\", \"flow_-2\", \"flow_-1\", \"flow_+1\", \"flow_+2\", \"speed_limit\"]\n",
        "speed_cols = [\"speed\", \"speed_-2\", \"speed_-1\",\"speed_+1\", \"speed_+2\"]\n",
        "flow_cols = [\"flow\", \"flow_-2\", \"flow_-1\", \"flow_+1\", \"flow_+2\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh4evfBugwJa",
        "colab_type": "text"
      },
      "source": [
        "### First resample to elmininate some noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVkBrcJDhVxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def resample_df(df, freq = \"10T\", method_speed = np.median, method_flow = np.sum):\n",
        "    copied = df.copy()\n",
        "    copied = copied.resample(freq).agg({\n",
        "           \"speed\": method_speed, \"speed_-2\": method_speed, \"speed_-1\": method_speed, \"speed_+1\": method_speed, \"speed_+2\": method_speed,\n",
        "           \"flow\": method_flow, \"flow_-2\": method_flow, \"flow_-1\": method_flow, \"flow_+1\": method_flow, \"flow_+2\": method_flow,\n",
        "           \"speed_limit\": np.median})\n",
        "    return copied"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJyIniCBhWIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r_df = resample_df(df, freq = \"10T\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M66yh3ektP7",
        "colab_type": "text"
      },
      "source": [
        "### Train test split. The final year is reserved for testing. (Val will be relevant later?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bibzm8V9kN0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_val_test_split(df, val_year, test_year):\n",
        "    # train, test\n",
        "    return df[(df.index.year != val_year) & (df.index.year != test_year)], df[df.index.year == val_year], df[df.index.year == test_year]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSeGBQtNq2GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val, test = train_val_test_split(r_df, 2018, 2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRftDaC5cuuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def log_transform(df):\n",
        "    copy = df.copy()\n",
        "    return np.log(copy.iloc[:, :-1].replace(0, 1e-15)).join(df.iloc[:, -1], how = 'inner')\n",
        "\n",
        "# Log transform. First set 0s to very low value 'cause you can't log 0.\n",
        "train_log = log_transform(train)\n",
        "val_log = log_transform(val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNoOO27FpHyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_mean(df, col):\n",
        "    # mean(100), mean(120)\n",
        "    return df.groupby(['speed_limit'])[col].mean().values\n",
        "\n",
        "def calc_sd(df, col):\n",
        "    # sd(100), sd(120)\n",
        "    return df.groupby(['speed_limit'])[col].std().values\n",
        "\n",
        "def normalize_df(df, cols):\n",
        "    copy = df.copy()\n",
        "    for col in cols:\n",
        "        # Find mean and sd for column\n",
        "        mean100, mean120 = calc_mean(copy, col)\n",
        "        sd100, sd120 = calc_sd(copy, col)\n",
        "        copy[col] = np.where(copy.speed_limit == 100, (copy[col] - mean100) / sd100, (copy[col] - mean120) / sd120)\n",
        "    return copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQQdWm2gywBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_norm = normalize_df(train_log, cols[:-1])\n",
        "val_norm = normalize_df(val_log, cols[:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DN1QmhV3D7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generates sequential 3D batches to feed to the model\n",
        "def generator(data, lookback, delay, min_index = 0, max_index = None, \n",
        "              shuffle = False, batch_size = 128, step = 1, target_col = 0):\n",
        "    # If max index not given, subtract prediction horizon - 1 (len to index) from last data point\n",
        "    if max_index is None:\n",
        "        max_index = len(data) - delay - 1\n",
        "    # Set i to first idx with valid lookback length behind it\n",
        "    i = min_index + lookback\n",
        "    while 1:\n",
        "        # Use shuffle for non-sequential data\n",
        "        if shuffle:\n",
        "            rows = np.random.randint(\n",
        "                min_index + lookback, max_index, size = batch_size)\n",
        "        # Else for sequential (time series)\n",
        "        else:\n",
        "            # Check if adding batch exceeds index bounds\n",
        "            if i + batch_size >= max_index:\n",
        "                # Return i to beginning\n",
        "                i = min_index + lookback\n",
        "            # Select next valid row range\n",
        "            rows = np.arange(i, min(i + batch_size, max_index))\n",
        "            # Increment i\n",
        "            i += len(rows)\n",
        "        # Initialize sample and target arrays\n",
        "        samples = np.zeros((len(rows),\n",
        "                            lookback // step,\n",
        "                            np.shape(data)[-1]))\n",
        "        targets = np.zeros((len(rows),))\n",
        "        # Generate samples, targets\n",
        "        for j, row in enumerate(rows):\n",
        "            indices = range(rows[j] - lookback, rows[j], step)\n",
        "            samples[j] = data[indices]\n",
        "            targets[j] = data[rows[j] + delay][target_col]\n",
        "        yield samples, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlfIKDZ634p9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator 'settings'\n",
        "\n",
        "train_data = train_norm.iloc[:, 0].values\n",
        "train_data = np.reshape(train_data, (np.shape(train_data)[0], 1))\n",
        "np.shape(train_data)\n",
        "\n",
        "lookback = 24 * 6 # 24 hours\n",
        "delay = 3 # 30 minutes\n",
        "step = 1\n",
        "batch_size = 128\n",
        "min_index_train = 0\n",
        "max_index_train = len(train_data)\n",
        "train_gen = generator(train_data,\n",
        "                      lookback = lookback,\n",
        "                      delay = delay,\n",
        "                      min_index = min_index_train,\n",
        "                      max_index = max_index_train,\n",
        "                      step = step, \n",
        "                      batch_size = batch_size,\n",
        "                      target_col = 0)\n",
        "\n",
        "\n",
        "val_data = val_norm.iloc[:, 0].values\n",
        "train_data = np.reshape(train_data, (np.shape(train_data)[0], 1))\n",
        "np.shape(train_data)\n",
        "\n",
        "min_index_val = 0\n",
        "max_index_val= len(val_data)\n",
        "val_gen = generator(val_data,\n",
        "                      lookback = lookback,\n",
        "                      delay = delay,\n",
        "                      min_index = min_index_val,\n",
        "                      max_index = max_index_val,\n",
        "                      step = step, \n",
        "                      batch_size = batch_size,\n",
        "                      target_col = 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoW9MvRG5b_i",
        "colab_type": "code",
        "outputId": "439e58ad-391c-464d-f7ff-8528474e248e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dXjc7sZ4pOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ML\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE9pIY2C-d7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# better way of setting up model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shfH2FV2-dCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = Input(shape=(dataset.n_timestep, dataset.n_feature))\n",
        "conv1 = Conv1D(filters=32,\n",
        "               kernel_size=8,\n",
        "               strides=1,\n",
        "               activation='relu')(input_layer)\n",
        "pool1 = MaxPooling1D(pool_size=4)(conv1)\n",
        "lstm1 = LSTM(32)(pool1)\n",
        "output_layer = Dense(1, activation='sigmoid')(lstm1)\n",
        "model = Model(inputs=input_layer, outputs=output_layer) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV0jk0hx5-fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Stacked LSTM with Dropout\n",
        "model = Sequential()\n",
        "#model.add(layers.Input(shape = (144, 10), batch_size = 128))\n",
        "model.add(layers.Conv1D(filters = 32, kernel_size = (1), activation = 'relu', input_shape = (144, 1)))\n",
        "model.add(layers.LSTM(32, \n",
        "                      dropout = 0.1,\n",
        "                      recurrent_dropout = 0.5,\n",
        "                      input_shape = (144, 32),#,\n",
        "                      #batch_size = 128,\n",
        "                      # input_shape = (None, data.shape[-1]),\n",
        "                      #stateful = True,\n",
        "                      return_sequences = True)) #,\n",
        "                      #return_state = True))\n",
        "model.add(layers.LSTM(32,\n",
        "                      dropout = 0.1,\n",
        "                      recurrent_dropout = 0.5,\n",
        "                      input_shape = (144, 32)))#,\n",
        "                      #batch_size = 128))#,\n",
        "                      # input_shape = (None, data.shape[-1]),\n",
        "                      #stateful = True))\n",
        "model.add(layers.Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmPmSOtpxx7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Stacked LSTM with Dropout\n",
        "model = Sequential()\n",
        "model.add(layers.Conv1D(filters = 32, kernel_size = (1), activation = 'relu', input_shape = (144, 1)))\n",
        "model.add(layers.LSTM(32, \n",
        "                      dropout = 0.1,\n",
        "                      recurrent_dropout = 0.5,\n",
        "                      input_shape = (144, 32),\n",
        "                      return_sequences = True))\n",
        "model.add(layers.LSTM(32,\n",
        "                      dropout = 0.1,\n",
        "                      recurrent_dropout = 0.5,\n",
        "                      input_shape = (144, 32)))\n",
        "model.add(layers.Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1DTzCXW7KSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = RMSprop(learning_rate = 0.001), loss = 'mse', metrics = ['mae', 'mape'])\n",
        "model.build(input_shape = (128, 144, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25uTTd6c8EaW",
        "colab_type": "code",
        "outputId": "07470c4d-74a8-40b4-e319-3900a4c765f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 144, 32)           64        \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 144, 32)           8320      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 16,737\n",
            "Trainable params: 16,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaA_aspq7BZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "6e3ec290-71f4-443c-fb5e-59db9e694217"
      },
      "source": [
        "history = model.fit(train_gen,\n",
        "                    steps_per_epoch = (((max_index_train + 1) // batch_size) + 1),\n",
        "                    epochs = 20)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-88907bd442bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(train_gen,\n\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_index_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     epochs = 20)\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0massert_not_namedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    848\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-3a0a27b43ced>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(data, lookback, delay, min_index, max_index, shuffle, batch_size, step, target_col)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlookback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (144) into shape (144,52560)"
          ]
        }
      ]
    }
  ]
}